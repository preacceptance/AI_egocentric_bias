} else if (p_value >= 0.001 & p_value < 0.01) {
stars <- '**'
} else if (p_value >= 0.01 & p_value < 0.05) {
stars <- '*'
} else if (p_value >= 0.05) {
stars <- 'ns'
}
return(stars)
}
split_self_AI <- function(s) {
pos <- regexpr("Self|AI", s)
if (pos > 0) {
match <- regmatches(s, pos)
rest_start <- pos + attr(pos, 'match.length')
rest <- substring(s, rest_start)
return(c(match, rest))
} else {
return(s)
}
}
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
# import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
d_raw <- read.csv('ai_curse_surveillance.csv', stringsAsFactors = FALSE)
#implement attention checks
dim(d_raw)[1]
d_raw <- subset(d_raw, (d_raw$attn_1 == 1 & d_raw$attn_2 == 2))
n_original <- dim(d_raw)
#implement comp checks
d_raw <- subset(d_raw, (d_raw$comp_images == 2))
n_final <- dim(d_raw)[1]; n_final
percent_excluded <- (n_original - n_final)/n_original; percent_excluded
## define new data frame to extract pre-processed data into:
d <- array(dim=c(n_final, 5))
colnames(d) <- c('agentCond', 'displayCond', 'capability', 'trust', 'why')
d <- as.data.frame(d, stringsAsFactors=FALSE)
## extract good data from the middle part of raw data in AV:
for(i in 1:dim(d_raw)[1]) {
curr <- d_raw[i,15:38][!is.na(d_raw[i,15:38])] # for a given row, get only the non-NA values
d[i,3:5] <- curr[curr!= ""][1:3] # and only the non-empty values
cond_ns <- names(d_raw[i,15:38])[which(d_raw[i,15:38] != "")]
conds <- strsplit(cond_ns[[1]], "_")[[1]][1]
d[i,1] <- split_self_AI(conds)[1]
d[i,2] <- split_self_AI(conds)[2]
}
# Merge demographic data
d <- cbind(d, d_raw[,40:47])
# Check counts for each condition
table(d$agentCond, d$displayCond)
#conver to numeric
d$capability <- as.numeric(d$capability)
d$trust <- as.numeric(d$trust)
#demographics
d_raw$age <- as.numeric(as.character(d_raw$age)); mean(d_raw$age, na.rm = TRUE)
table(d_raw$gender)[1]/sum(table(d_raw$gender))
## ================================================================================================================
##                                              PLOT
## ================================================================================================================
# Define the variable names and titles
title_size <- 16
axis_size <- 10
# Ensure `factor_Demo` and `factor_AI` are properly set
d$displayCond <- factor(d$displayCond, levels = c("Present", "Adjacent", "Absent", "Baseline"),
labels = c("image-annotated", "image-adjacent", "annotations-only", "baseline-image"))
d$agentCond <- factor(d$agentCond, levels = c("Self", "AI"))
# Function to create the plots
plotter <- function(data, value_column, input_title) {
p <- ggplot(data, aes(x = displayCond, y = get(value_column), fill = agentCond)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.9), color = "black", size = 0.4) +
geom_errorbar(stat = "summary", fun.data = "mean_cl_boot",
position = position_dodge(width = 0.9), width = 0.2) +
scale_fill_manual(values = c("lightgrey", "darkgrey"), labels = c("Self", "AI")) +
labs(title = input_title) +  # Remove x-axis and y-axis small labels
theme_bw() +
theme(
text = element_text(size = title_size),
axis.text.x = element_text(size = axis_size, angle = 45, hjust = 1),  # Diagonal x-axis labels
axis.text.y = element_text(size = axis_size),
axis.title.x = element_blank(),  # Remove x-axis label
axis.title.y = element_blank(),  # Remove y-axis label
plot.title = element_text(size = title_size, hjust = 0.5),
legend.title = element_blank(),
legend.position = "top"
) +
geom_hline(yintercept = 50, linetype = "dotted") +  # Add dotted line at y = 50
scale_y_continuous(limits = c(0, 100))  # Set y-axis limits to 0-100
return(p)
}
# Create plots for Trust and Capability
p1 <- plotter(d, "capability", "Capability")
p2 <- plotter(d, "trust", "Trust")
# Arrange the plots side by side
figure <- ggarrange(p1, p2, nrow = 1, ncol = 2)
# Add annotations to the combined figure
annotated_figure <- annotate_figure(figure,
left = text_grob("Mean Rating", color = "black", face = "plain", size = 26, rot = 90),
bottom = text_grob("Image Annotation Condition", size = 26, vjust = -.1))
ggsave("figure7.pdf", annotated_figure, width = 7, height = 5, dpi = 300)
# Create the 'figures' directory if it doesn't exist
if (!dir.exists("figures")) {
dir.create("figures")
}
# Move the PDF to the 'figures' subfolder
file.rename("figure7.pdf", "figures/figure7.pdf")
## ================================================================================================================
##                                        CAPABILITY
## ================================================================================================================
# Fit the ANOVA model
capability_model <- aov(capability ~ agentCond*displayCond, data = d)
summary(capability_model)
eta_squared(capability_model)
#main effect of agentCond
tapply(d$capability, d$agentCond, mean)
tapply(d$capability, d$agentCond, sd)
# AI Conditions - Pairwise comparisons across all conditions (Capability)
ai_data <- d[d$agentCond == "AI", ]
ai_conditions <- split(ai_data, ai_data$displayCond)
ai_results_capability <- list()
for (cond1 in names(ai_conditions)) {
for (cond2 in names(ai_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
ai_results_capability[[comparison_name]] <- list(t.test(
ai_conditions[[cond1]]$capability, ai_conditions[[cond2]]$capability
),
cohen.d(
ai_conditions[[cond1]]$capability,
ai_conditions[[cond2]]$capability
))
}
}
}
# Self Conditions - Pairwise comparisons across all conditions (Capability)
self_data <- d[d$agentCond == "Self", ]
self_conditions <- split(self_data, self_data$displayCond)
self_results_capability <- list()
for (cond1 in names(self_conditions)) {
for (cond2 in names(self_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
self_results_capability[[comparison_name]] <- list(t.test(
self_conditions[[cond1]]$capability, self_conditions[[cond2]]$capability
),
cohen.d(
self_conditions[[cond1]]$capability,
self_conditions[[cond2]]$capability
))
}
}
}
ai_results_capability
self_results_capability
# Within-agent comparisons for Capability and Trust
tapply(d$capability, list(d$agentCond, d$displayCond), mean)
tapply(d$capability, list(d$agentCond, d$displayCond), sd)
# Initialize lists for AI vs. Self comparisons and midpoint tests
capability_t_tests <- list()
capability_midpoint_tests <- list()
# Loop through each demonstration type for Capability
for (demo in levels(d$displayCond)) {
# Subset data for the current demonstration type
subset_data <- d[d$displayCond == demo, ]
# AI vs. Self t-test for Capability
capability_t_tests[[demo]] <- t.test(capability ~ agentCond, data = subset_data)
# Midpoint t-test for Capability
capability_midpoint_tests[[demo]] <- t.test(subset_data$capability, mu = 50)
}
capability_t_tests
capability_midpoint_tests
## ================================================================================================================
##                                        TRUST
## ================================================================================================================
# Fit the ANOVA model
trust_model <- aov(trust ~ agentCond*displayCond, data = d)
summary(trust_model)
eta_squared(trust_model)
#main effect of agentCond
tapply(d$trust, d$agentCond, mean)
tapply(d$trust, d$agentCond, sd)
# AI Conditions - Pairwise comparisons across all conditions (Capability)
ai_results_trust <- list()
for (cond1 in names(ai_conditions)) {
for (cond2 in names(ai_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
ai_results_capability[[comparison_name]] <- list(t.test(
ai_conditions[[cond1]]$trust, ai_conditions[[cond2]]$trust
),
cohen.d(
ai_conditions[[cond1]]$trust,
ai_conditions[[cond2]]$trust
))
}
}
}
# Self Conditions - Pairwise comparisons across all conditions (Trust)
self_results_trust <- list()
for (cond1 in names(self_conditions)) {
for (cond2 in names(self_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
self_results_capability[[comparison_name]] <- list(t.test(
self_conditions[[cond1]]$trust, self_conditions[[cond2]]$trust
),
cohen.d(
self_conditions[[cond1]]$trust,
self_conditions[[cond2]]$trust
))
}
}
}
ai_results_trust
self_results_trust
ai_results_trust
## Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV SCENARIOS | BETWEEN SUBJECTS
## ================================================================================================================
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc',
'effsize',         # effect size
'reshape2',         # reshaping data
'rlang',
'rstatix',
'scales',
'tidyverse',
'mediation'
)
library("lmerTest")
library(dplyr)
mediation <- TRUE #perform mediation analysis
## ================================================================================================================
##                                              FUNCTIONS
## ================================================================================================================
# Define the create_stars function
create_stars <- function(p_value) {
stars <- ''
if (p_value < 0.001) {
stars <- '***'
} else if (p_value >= 0.001 & p_value < 0.01) {
stars <- '**'
} else if (p_value >= 0.01 & p_value < 0.05) {
stars <- '*'
} else if (p_value >= 0.05) {
stars <- 'ns'
}
return(stars)
}
split_self_AI <- function(s) {
pos <- regexpr("Self|AI", s)
if (pos > 0) {
match <- regmatches(s, pos)
rest_start <- pos + attr(pos, 'match.length')
rest <- substring(s, rest_start)
return(c(match, rest))
} else {
return(s)
}
}
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
# import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
d_raw <- read.csv('ai_curse_surveillance.csv', stringsAsFactors = FALSE)
#implement attention checks
dim(d_raw)[1]
d_raw <- subset(d_raw, (d_raw$attn_1 == 1 & d_raw$attn_2 == 2))
n_original <- dim(d_raw)
#implement comp checks
d_raw <- subset(d_raw, (d_raw$comp_images == 2))
n_final <- dim(d_raw)[1]; n_final
percent_excluded <- (n_original - n_final)/n_original; percent_excluded
## define new data frame to extract pre-processed data into:
d <- array(dim=c(n_final, 5))
colnames(d) <- c('agentCond', 'displayCond', 'capability', 'trust', 'why')
d <- as.data.frame(d, stringsAsFactors=FALSE)
## extract good data from the middle part of raw data in AV:
for(i in 1:dim(d_raw)[1]) {
curr <- d_raw[i,15:38][!is.na(d_raw[i,15:38])] # for a given row, get only the non-NA values
d[i,3:5] <- curr[curr!= ""][1:3] # and only the non-empty values
cond_ns <- names(d_raw[i,15:38])[which(d_raw[i,15:38] != "")]
conds <- strsplit(cond_ns[[1]], "_")[[1]][1]
d[i,1] <- split_self_AI(conds)[1]
d[i,2] <- split_self_AI(conds)[2]
}
# Merge demographic data
d <- cbind(d, d_raw[,40:47])
# Check counts for each condition
table(d$agentCond, d$displayCond)
#conver to numeric
d$capability <- as.numeric(d$capability)
d$trust <- as.numeric(d$trust)
#demographics
d_raw$age <- as.numeric(as.character(d_raw$age)); mean(d_raw$age, na.rm = TRUE)
table(d_raw$gender)[1]/sum(table(d_raw$gender))
## ================================================================================================================
##                                              PLOT
## ================================================================================================================
# Define the variable names and titles
title_size <- 16
axis_size <- 10
# Ensure `factor_Demo` and `factor_AI` are properly set
d$displayCond <- factor(d$displayCond, levels = c("Present", "Adjacent", "Absent", "Baseline"),
labels = c("image-annotated", "image-adjacent", "annotations-only", "baseline-image"))
d$agentCond <- factor(d$agentCond, levels = c("Self", "AI"))
# Function to create the plots
plotter <- function(data, value_column, input_title) {
p <- ggplot(data, aes(x = displayCond, y = get(value_column), fill = agentCond)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.9), color = "black", size = 0.4) +
geom_errorbar(stat = "summary", fun.data = "mean_cl_boot",
position = position_dodge(width = 0.9), width = 0.2) +
scale_fill_manual(values = c("lightgrey", "darkgrey"), labels = c("Self", "AI")) +
labs(title = input_title) +  # Remove x-axis and y-axis small labels
theme_bw() +
theme(
text = element_text(size = title_size),
axis.text.x = element_text(size = axis_size, angle = 45, hjust = 1),  # Diagonal x-axis labels
axis.text.y = element_text(size = axis_size),
axis.title.x = element_blank(),  # Remove x-axis label
axis.title.y = element_blank(),  # Remove y-axis label
plot.title = element_text(size = title_size, hjust = 0.5),
legend.title = element_blank(),
legend.position = "top"
) +
geom_hline(yintercept = 50, linetype = "dotted") +  # Add dotted line at y = 50
scale_y_continuous(limits = c(0, 100))  # Set y-axis limits to 0-100
return(p)
}
# Create plots for Trust and Capability
p1 <- plotter(d, "capability", "Capability")
p2 <- plotter(d, "trust", "Trust")
# Arrange the plots side by side
figure <- ggarrange(p1, p2, nrow = 1, ncol = 2)
# Add annotations to the combined figure
annotated_figure <- annotate_figure(figure,
left = text_grob("Mean Rating", color = "black", face = "plain", size = 26, rot = 90),
bottom = text_grob("Image Annotation Condition", size = 26, vjust = -.1))
ggsave("figure7.pdf", annotated_figure, width = 7, height = 5, dpi = 300)
# Create the 'figures' directory if it doesn't exist
if (!dir.exists("figures")) {
dir.create("figures")
}
# Move the PDF to the 'figures' subfolder
file.rename("figure7.pdf", "figures/figure7.pdf")
## ================================================================================================================
##                                        CAPABILITY
## ================================================================================================================
# Fit the ANOVA model
capability_model <- aov(capability ~ agentCond*displayCond, data = d)
summary(capability_model)
eta_squared(capability_model)
#main effect of agentCond
tapply(d$capability, d$agentCond, mean)
tapply(d$capability, d$agentCond, sd)
# AI Conditions - Pairwise comparisons across all conditions (Capability)
ai_data <- d[d$agentCond == "AI", ]
ai_conditions <- split(ai_data, ai_data$displayCond)
ai_results_capability <- list()
for (cond1 in names(ai_conditions)) {
for (cond2 in names(ai_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
ai_results_capability[[comparison_name]] <- list(t.test(
ai_conditions[[cond1]]$capability, ai_conditions[[cond2]]$capability
),
cohen.d(
ai_conditions[[cond1]]$capability,
ai_conditions[[cond2]]$capability
))
}
}
}
# Self Conditions - Pairwise comparisons across all conditions (Capability)
self_data <- d[d$agentCond == "Self", ]
self_conditions <- split(self_data, self_data$displayCond)
self_results_capability <- list()
for (cond1 in names(self_conditions)) {
for (cond2 in names(self_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
self_results_capability[[comparison_name]] <- list(t.test(
self_conditions[[cond1]]$capability, self_conditions[[cond2]]$capability
),
cohen.d(
self_conditions[[cond1]]$capability,
self_conditions[[cond2]]$capability
))
}
}
}
ai_results_capability
self_results_capability
# Within-agent comparisons for Capability and Trust
tapply(d$capability, list(d$agentCond, d$displayCond), mean)
tapply(d$capability, list(d$agentCond, d$displayCond), sd)
# Initialize lists for AI vs. Self comparisons and midpoint tests
capability_t_tests <- list()
capability_midpoint_tests <- list()
# Loop through each demonstration type for Capability
for (demo in levels(d$displayCond)) {
# Subset data for the current demonstration type
subset_data <- d[d$displayCond == demo, ]
# AI vs. Self t-test for Capability
capability_t_tests[[demo]] <- t.test(capability ~ agentCond, data = subset_data)
# Midpoint t-test for Capability
capability_midpoint_tests[[demo]] <- t.test(subset_data$capability, mu = 50)
}
capability_t_tests
capability_midpoint_tests
## ================================================================================================================
##                                        TRUST
## ================================================================================================================
# Fit the ANOVA model
trust_model <- aov(trust ~ agentCond*displayCond, data = d)
summary(trust_model)
eta_squared(trust_model)
#main effect of agentCond
tapply(d$trust, d$agentCond, mean)
tapply(d$trust, d$agentCond, sd)
# AI Conditions - Pairwise comparisons across all conditions (Capability)
ai_results_trust <- list()
for (cond1 in names(ai_conditions)) {
for (cond2 in names(ai_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
ai_results_trust[[comparison_name]] <- list(t.test(
ai_conditions[[cond1]]$trust, ai_conditions[[cond2]]$trust
),
cohen.d(
ai_conditions[[cond1]]$trust,
ai_conditions[[cond2]]$trust
))
}
}
}
# Self Conditions - Pairwise comparisons across all conditions (Trust)
self_results_trust <- list()
for (cond1 in names(self_conditions)) {
for (cond2 in names(self_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
self_results_trust[[comparison_name]] <- list(t.test(
self_conditions[[cond1]]$trust, self_conditions[[cond2]]$trust
),
cohen.d(
self_conditions[[cond1]]$trust,
self_conditions[[cond2]]$trust
))
}
}
}
ai_results_trust
self_results_trust
self_results_trust
self_results_trust
ai_results_trust
# Within-agent comparisons for Capability and Trust
tapply(d$trust, list(d$agentCond, d$displayCond), mean)
tapply(d$trust, list(d$agentCond, d$displayCond), sd)
# Initialize lists for AI vs. Self comparisons and midpoint tests
trust_t_tests <- list()
trust_midpoint_tests <- list()
# Loop through each demonstration type for Capability
for (demo in levels(d$displayCond)) {
# Subset data for the current demonstration type
subset_data <- d[d$displayCond == demo, ]
# AI vs. Self t-test for Capability
trust_t_tests[[demo]] <- t.test(trust ~ agentCond, data = subset_data)
# Midpoint t-test for Capability
trust_midpoint_tests[[demo]] <- t.test(subset_data$trust, mu = 50)
}
trust_t_tests
d_ai <- subset(d, d$agentCond=='AI')
cor.test(d_ai$capability, d_ai$trust)
# Subset data for Mediation Analysis  (Faded, Adjacent, and Present conditions)
d_ai$cond_n <- ifelse(d_ai$displayCond=='annotations-only', 0,
ifelse(d_ai$displayCond=='image-annotated', 1,
ifelse(d_ai$displayCond=='image-adjacent', 2,
ifelse(d_ai$displayCond=='baseline-image', 3, NA))))
# Mediation Analysis
if(mediation) {
source("../common_scripts/process.R")
process(data = d_ai, y = "trust", x = "cond_n",
m = "capability", model = 4, effsize = 1, mcx = 1, total = 1, stand = 1,
contrast = 1, boot = 10000, modelbt = 1, seed = 654321)
}
cor.test(d_ai$capability, d_ai$trust)
