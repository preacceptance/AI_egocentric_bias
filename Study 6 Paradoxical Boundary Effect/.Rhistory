scale_y_continuous(limits = c(0, 100))  # Set y-axis limits to 0-100
return(p)
}
# Create plots for Trust and Capability
p1 <- plotter(d, "capability", "Capability")
p2 <- plotter(d, "trust", "Trust")
# Arrange the plots side by side
figure <- ggarrange(p1, p2, nrow = 1, ncol = 2)
# Add annotations to the combined figure
annotated_figure <- annotate_figure(figure,
left = text_grob("Mean Rating", color = "black", face = "plain", size = 26, rot = 90),
bottom = text_grob("Image Annotation Condition", size = 26, vjust = -.1))
ggsave("figure7.pdf", annotated_figure, width = 7, height = 5, dpi = 300)
# Create the 'figures' directory if it doesn't exist
if (!dir.exists("figures")) {
dir.create("figures")
}
# Move the PDF to the 'figures' subfolder
file.rename("figure7.pdf", "figures/figure7.pdf")
## ================================================================================================================
##                                        CAPABILITY
## ================================================================================================================
# Fit the ANOVA model
capability_model <- aov(capability ~ agentCond*displayCond, data = d)
summary(capability_model)
eta_squared(capability_model)
#main effect of agentCond
tapply(d$capability, d$agentCond, mean)
tapply(d$capability, d$agentCond, sd)
# AI Conditions - Pairwise comparisons across all conditions (Capability)
ai_data <- d[d$agentCond == "AI", ]
ai_conditions <- split(ai_data, ai_data$displayCond)
ai_results_capability <- list()
for (cond1 in names(ai_conditions)) {
for (cond2 in names(ai_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
ai_results_capability[[comparison_name]] <- list(t.test(
ai_conditions[[cond1]]$capability, ai_conditions[[cond2]]$capability
),
cohen.d(
ai_conditions[[cond1]]$capability,
ai_conditions[[cond2]]$capability
))
}
}
}
# Self Conditions - Pairwise comparisons across all conditions (Capability)
self_data <- d[d$agentCond == "Self", ]
self_conditions <- split(self_data, self_data$displayCond)
self_results_capability <- list()
for (cond1 in names(self_conditions)) {
for (cond2 in names(self_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
self_results_capability[[comparison_name]] <- list(t.test(
self_conditions[[cond1]]$capability, self_conditions[[cond2]]$capability
),
cohen.d(
self_conditions[[cond1]]$capability,
self_conditions[[cond2]]$capability
))
}
}
}
ai_results_capability
self_results_capability
# Within-agent comparisons for Capability and Trust
tapply(d$capability, list(d$agentCond, d$displayCond), mean)
tapply(d$capability, list(d$agentCond, d$displayCond), sd)
# Initialize lists for AI vs. Self comparisons and midpoint tests
capability_t_tests <- list()
capability_midpoint_tests <- list()
# Loop through each demonstration type for Capability
for (demo in levels(d$displayCond)) {
# Subset data for the current demonstration type
subset_data <- d[d$displayCond == demo, ]
# AI vs. Self t-test for Capability
capability_t_tests[[demo]] <- t.test(capability ~ agentCond, data = subset_data)
# Midpoint t-test for Capability
capability_midpoint_tests[[demo]] <- t.test(subset_data$capability, mu = 50)
}
capability_t_tests
capability_midpoint_tests
## ================================================================================================================
##                                        TRUST
## ================================================================================================================
# Fit the ANOVA model
trust_model <- aov(trust ~ agentCond*displayCond, data = d)
summary(trust_model)
eta_squared(trust_model)
#main effect of agentCond
tapply(d$trust, d$agentCond, mean)
tapply(d$trust, d$agentCond, sd)
# AI Conditions - Pairwise comparisons across all conditions (Capability)
ai_results_trust <- list()
for (cond1 in names(ai_conditions)) {
for (cond2 in names(ai_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
ai_results_trust[[comparison_name]] <- list(t.test(
ai_conditions[[cond1]]$trust, ai_conditions[[cond2]]$trust
),
cohen.d(
ai_conditions[[cond1]]$trust,
ai_conditions[[cond2]]$trust
))
}
}
}
# Self Conditions - Pairwise comparisons across all conditions (Trust)
self_results_trust <- list()
for (cond1 in names(self_conditions)) {
for (cond2 in names(self_conditions)) {
if (cond1 != cond2) {
comparison_name <- paste(cond1, "vs", cond2)
self_results_trust[[comparison_name]] <- list(t.test(
self_conditions[[cond1]]$trust, self_conditions[[cond2]]$trust
),
cohen.d(
self_conditions[[cond1]]$trust,
self_conditions[[cond2]]$trust
))
}
}
}
ai_results_trust
self_results_trust
# Within-agent comparisons for Capability and Trust
tapply(d$trust, list(d$agentCond, d$displayCond), mean)
tapply(d$trust, list(d$agentCond, d$displayCond), sd)
# Initialize lists for AI vs. Self comparisons and midpoint tests
trust_t_tests <- list()
trust_midpoint_tests <- list()
# Loop through each demonstration type for Capability
for (demo in levels(d$displayCond)) {
# Subset data for the current demonstration type
subset_data <- d[d$displayCond == demo, ]
# AI vs. Self t-test for Capability
trust_t_tests[[demo]] <- t.test(trust ~ agentCond, data = subset_data)
# Midpoint t-test for Capability
trust_midpoint_tests[[demo]] <- t.test(subset_data$trust, mu = 50)
}
trust_t_tests
trust_midpoint_tests
## ================================================================================================================
##                                              MEDIATION
## ================================================================================================================
d_ai <- subset(d, d$agentCond=='AI')
cor.test(d_ai$capability, d_ai$trust)
# Subset data for Mediation Analysis  (Faded, Adjacent, and Present conditions)
d_ai$cond_n <- ifelse(d_ai$displayCond=='annotations-only', 0,
ifelse(d_ai$displayCond=='image-annotated', 1,
ifelse(d_ai$displayCond=='image-adjacent', 2,
ifelse(d_ai$displayCond=='baseline-image', 3, NA))))
process(data = d_ai, y = "trust", x = "cond_n",
m =c("capability"), w =c("AI_Familiarity_1"), model = 7, effsize = 1, total = 1, stand = 1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
source("../common_scripts/process.R")
process(data = d_ai, y = "trust", x = "cond_n",
m =c("capability"), w =c("AI_Familiarity_1"), model = 7, effsize = 1, total = 1, stand = 1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
process(data = d_ai, y = "trust", x = "cond_n",
m = "capability", model = 4, effsize = 1, mcx = 1, total = 1, stand = 1,
contrast = 1, boot = 10000, modelbt = 1, seed = 654321)
process(data = d_ai, y = "trust", x = "cond_n",
m =c("capability"), w =c("AI_Familiarity_1"), model = 7, effsize = 1, total = 1, stand = 1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
d_ai$AI_Familiarity_1
d_ai$AI_Familiarity_1 <- as.numeric(d_ai$AI_Familiarity_1)
d_ai$Visual_Familiarity_1 <- as.numeric(d_ai$Visual_Familiarity_1)
process(data = d_ai, y = "trust", x = "cond_n",
m =c("capability"), w =c("AI_Familiarity_1"), model = 7, effsize = 1, total = 1, stand = 1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
process(data = d_ai, y = "trust", x = "cond_n",
m =c("capability"), w =c("Visual_Familiarity_1"), model = 7, effsize = 1, total = 1, stand = 1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
## Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV SCENARIOS | BETWEEN SUBJECTS
## ================================================================================================================
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc',
'effsize',         # effect size
'reshape2',         # reshaping data
'rlang',
'rstatix',
'scales',
'tidyverse',
'mediation'
)
library("lmerTest")
library(dplyr)
mediation <- TRUE #perform mediation analysis
## ================================================================================================================
##                                              FUNCTIONS
## ================================================================================================================
# Define the create_stars function
create_stars <- function(p_value) {
stars <- ''
if (p_value < 0.001) {
stars <- '***'
} else if (p_value >= 0.001 & p_value < 0.01) {
stars <- '**'
} else if (p_value >= 0.01 & p_value < 0.05) {
stars <- '*'
} else if (p_value >= 0.05) {
stars <- 'ns'
}
return(stars)
}
split_self_AI <- function(s) {
pos <- regexpr("Self|AI", s)
if (pos > 0) {
match <- regmatches(s, pos)
rest_start <- pos + attr(pos, 'match.length')
rest <- substring(s, rest_start)
return(c(match, rest))
} else {
return(s)
}
}
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
# import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
d_raw <- read.csv('ai_curse_surveillance.csv', stringsAsFactors = FALSE)
#implement attention checks
dim(d_raw)[1]
d_raw <- subset(d_raw, (d_raw$attn_1 == 1 & d_raw$attn_2 == 2))
n_original <- dim(d_raw)
colnames(d_raw)
1307/8
1307/10
## Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV SCENARIOS | BETWEEN SUBJECTS
## ================================================================================================================
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc',
'effsize',         # effect size
'reshape2',         # reshaping data
'rlang',
'rstatix',
'scales',
'tidyverse',
'mediation'
)
library("lmerTest")
library(dplyr)
mediation <- TRUE #perform mediation analysis
## ================================================================================================================
##                                              FUNCTIONS
## ================================================================================================================
# Define the create_stars function
create_stars <- function(p_value) {
stars <- ''
if (p_value < 0.001) {
stars <- '***'
} else if (p_value >= 0.001 & p_value < 0.01) {
stars <- '**'
} else if (p_value >= 0.01 & p_value < 0.05) {
stars <- '*'
} else if (p_value >= 0.05) {
stars <- 'ns'
}
return(stars)
}
split_self_AI <- function(s) {
pos <- regexpr("Self|AI", s)
if (pos > 0) {
match <- regmatches(s, pos)
rest_start <- pos + attr(pos, 'match.length')
rest <- substring(s, rest_start)
return(c(match, rest))
} else {
return(s)
}
}
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
# import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
d_raw <- read.csv('ai_curse_surveillance.csv', stringsAsFactors = FALSE)
#implement attention checks
dim(d_raw)[1]
d_raw <- subset(d_raw, (d_raw$attn_1 == 1 & d_raw$attn_2 == 2))
n_original <- dim(d_raw)
n_original
1140/8
1140/8
## Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV SCENARIOS | BETWEEN SUBJECTS
## ================================================================================================================
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc',
'effsize',         # effect size
'reshape2',         # reshaping data
'rlang',
'rstatix',
'scales',
'tidyverse',
'mediation'
)
library("lmerTest")
library(dplyr)
mediation <- TRUE #perform mediation analysis
## ================================================================================================================
##                                              FUNCTIONS
## ================================================================================================================
# Define the create_stars function
create_stars <- function(p_value) {
stars <- ''
if (p_value < 0.001) {
stars <- '***'
} else if (p_value >= 0.001 & p_value < 0.01) {
stars <- '**'
} else if (p_value >= 0.01 & p_value < 0.05) {
stars <- '*'
} else if (p_value >= 0.05) {
stars <- 'ns'
}
return(stars)
}
split_self_AI <- function(s) {
pos <- regexpr("Self|AI", s)
if (pos > 0) {
match <- regmatches(s, pos)
rest_start <- pos + attr(pos, 'match.length')
rest <- substring(s, rest_start)
return(c(match, rest))
} else {
return(s)
}
}
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
# import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
d_raw <- read.csv('AI_Curse_Object_Relations.csv', stringsAsFactors = FALSE)
dim(d_raw)
#implement attention checks
d_raw <- subset(d_raw, (d_raw$attn_1 == 1 & d_raw$attn_2 == 2))
n_original <- dim(d_raw); n_original
1106/8
## Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV SCENARIOS | BETWEEN SUBJECTS
## ================================================================================================================
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'ggpubr',          # arrange plots in a grid
'lme4',            # functions for fitting linear regression models
'rstatix',         # summary statistics and data visualization tools
'dplyr'            # data manipulation
)
library("lmerTest")
library(dplyr)
mediation <- FALSE
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
# import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d_raw <- read.csv('AI_Curse_Intervention_Numeric.csv')
## number of participants BEFORE exclusions:
n_original <- dim(d_raw)[1] # extracting number of rows only, not columns
n_original
## perform attention exclusions:
d_raw <- subset(d_raw, ( d_raw$attn_1 == 1 & d_raw$attn_2 == 2))
n_original <- dim(d_raw)[1]; n_original
571/4
## Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV SCENARIOS | WITHIN SUBJECTS
## ================================================================================================================
# Clear workspace and set options
rm(list = ls())
options(download.file.method="libcurl")
# Install and load necessary packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load(
'ggplot2',      # For plotting
'dplyr',        # For data manipulation
'lme4',         # For mixed-effects models
'ggpubr',       # For arranging ggplot figures
'ltm',          # For calculating Cronbach's alpha
'tidyr',        # For data tidying
'effsize',      # For effect size calculations
'pwr',          # For power analysis
'Hmisc',        # For miscellaneous functions like Cronbach's alpha
'reshape2',     # For reshaping data
'rstatix',      # For statistical tests
'scales',       # For scaling data in plots
'mediation',    # For mediation analysis
'lmerTest'      # For linear mixed-effects models with p-values
)
library("lmerTest")
library(dplyr)
# Import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
d_raw <- read.csv('AI_Curse_Video_Behavior.csv')
# Number of participants before exclusions
n_original <- dim(d_raw)[1]; n_original
d_raw <- subset(d_raw, ( d_raw$att_1 == 2 & d_raw$att_2 == 2 ))
n_final <- dim(d_raw)[1]; n_final
## Harvard Business School, Ethical Intelligence Lab
## ================================================================================================================
##                                DATA ANALYSIS | AV SCENARIOS | BETWEEN SUBJECTS
## ================================================================================================================
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'ggpubr',          # arrange plots in a grid
'lme4',            # functions for fitting linear regression models
'rstatix',         # summary statistics and data visualization tools
'dplyr',           # data manipulation
'rlang'            # programming tools for tidy evaluation
)
mediation <- FALSE
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
# import data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d_raw <- read.csv('AI_Curse_Unannotated_vs_Annotated.csv')
## number of participants BEFORE exclusions:
n_original <- dim(d_raw)[1] # extracting number of rows only, not columns
n_original
## perform attention exclusions:
d_raw <- subset(d_raw, ( d_raw$attn_1 == 1 & d_raw$attn_2 == 2 & d_raw$comp_images == 1))
n_original <- dim(d_raw)[1]; n_original
294/2
